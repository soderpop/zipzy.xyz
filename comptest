#Copyright (c) 2023 August 3rd Alexander Edward Brygider all rights reserved.

import numpy as np
from PIL import Image
import colorsys
import gzip
import os
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import time
import gzip


# Compress data in chunks using gzip
def compress_data(data_path, progress_bar):
    with open(data_path, 'rb') as file:
        with gzip.open("compressed_data.gz", 'wb') as compressed_file:
            compressed_file.write(file.read())
    progress_bar.update(100)

# Decompress data in chunks using gzip
def decompress_data(progress_bar):
    with gzip.open("compressed_data.gz", 'rb') as compressed_file:
        with open("decompressed_data", 'wb') as decompressed_file:
            decompressed_file.write(compressed_file.read())
    progress_bar.update(100)


# Embed compressed data efficiently
def embed_compressed_data(carpet, compressed_data, metadata_degrees, data_values, batch_size, progress_bar):
    carpet_data = np.array(carpet)
    data_index = 0
    num_pixels = carpet_data.shape[0] * carpet_data.shape[1]
    start_time = time.time()

    for i in range(num_pixels):
        if data_index >= len(compressed_data):
            break

        y, x = divmod(i, carpet_data.shape[1])
        bit = int(compressed_data[data_index])  # Extract one bit from the compressed data
        carpet_data[x, y, 0] = (carpet_data[x, y, 0] & 0xFE) | bit

        degree = metadata_degrees[data_index % len(metadata_degrees)]
        h, s, v = colorsys.rgb_to_hsv(carpet_data[x, y, 0] / 255.0, carpet_data[x, y, 1] / 255.0, carpet_data[x, y, 2] / 255.0)
        h = (h + degree / 360) % 1.0
        v = data_values[data_index % len(data_values)]
        carpet_data[x, y, :] = [int(val * 255) for val in colorsys.hsv_to_rgb(h, s, v)]

        data_index += 1
        progress_bar.update(1)

        if data_index % batch_size == 0:
            carpet_data = carpet_data[:, :, :data_index]

        # Update progress every second
        if time.time() - start_time > 1:
            progress = data_index / len(compressed_data) * 100
            progress_bar.update(progress - progress_bar.n)
            start_time = time.time()

    progress_bar.update(100 - progress_bar.n)

    return Image.fromarray(carpet_data)

# Modify the main function to handle large files
def main():
    while True:    
        print("Lossless Compression/Decompression App")
        print("--------------------------------------")
        print("1. Compress Data")
        print("2. Decompress Data")
        choice = input("Enter your choice (1/2): ")

        if choice == "1":
            data_path = input("Enter the file path you want to compress: ")

            # Compress data in chunks using gzip with concurrent execution
            with ThreadPoolExecutor(max_workers=2) as executor:
                progress_bar = tqdm(total=100, unit="percent", unit_scale=True)
                future = executor.submit(compress_data, data_path, progress_bar)
                future.result()
                progress_bar.close()

            num_colors = 5  # Number of equidistant colors
            metadata_degrees = [i * 360 / num_colors for i in range(num_colors)]
            data_values = [0.25, 0.5, 0.75]  # Example data_values

            new_width = int(256 * 0.004)
            new_height = int(256 * 0.004)

            if new_width > 0 and new_height > 0:
                carpet = Image.new("RGB", (256, 256), (0, 0, 0))
                carpet = carpet.resize((new_width, new_height), Image.LANCZOS)

                # Embed compressed data efficiently
                with open("compressed_data.gz", "rb") as compressed_file:
                    compressed_data = compressed_file.read()

                progress_bar = tqdm(total=100, unit="percent", unit_scale=True)
                embedded_canvas = embed_compressed_data(carpet.copy(), compressed_data, metadata_degrees, data_values, batch_size=1000, progress_bar=progress_bar)
                carpet.paste(embedded_canvas, (0, 0))
                progress_bar.close()

                # Save the image to the current directory
                compressed_image_path = input("Enter the file name you want to save the compressed image as (with extension .png): ")
                carpet.save(compressed_image_path)

                # Calculate the compression ratio
                original_size = os.path.getsize(data_path)
                compressed_size = os.path.getsize(compressed_image_path)
                compression_ratio = original_size / compressed_size

                print(f"Compression completed. Compressed image saved as '{compressed_image_path}'")
                print(f"Compression Ratio: {compression_ratio:.4f}")

                # Delete the original file
                os.remove(data_path)

            else:
                print("Error: The zoom factor is too small.")

        elif choice == "2":
            compressed_image_path = input("Enter the path to the compressed image (PNG): ")
            carpet = Image.open(compressed_image_path)

            # Decompress the data with concurrent execution
            with ThreadPoolExecutor(max_workers=2) as executor:
                progress_bar = tqdm(total=100, unit="percent", unit_scale=True)
                future = executor.submit(decompress_data, progress_bar)
                future.result()
                progress_bar.close()

            print("Decompression completed.")

        else:
            print("Invalid choice. Please enter '1' for compression or '2' for decompression.")


if __name__ == "__main__":
    main()
